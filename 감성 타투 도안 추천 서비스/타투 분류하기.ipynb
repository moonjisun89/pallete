{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 폴더명 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './추려추려/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cache_avhash', '고래', '꽃', '나비', '달', '십자가', '하트']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tattoo_categori_list = os.listdir(folder_path)\n",
    "tattoo_categori_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train, validation, test 셋트로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_avhash 777\n",
      "고래 100\n",
      "꽃 100\n",
      "나비 100\n",
      "달 147\n",
      "십자가 115\n",
      "하트 100\n"
     ]
    }
   ],
   "source": [
    "tattoo_categori_list = os.listdir(folder_path)\n",
    "for folder_name in tattoo_categori_list :\n",
    "    print(folder_name, len(os.listdir(folder_path+folder_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5(train) : 2(validation) : 3(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(folder_path,'train')\n",
    "validation_path = os.path.join(folder_path,'validation')\n",
    "test_path = os.path.join(folder_path,'test')\n",
    "print(train_path) \n",
    "print(validation_path)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw-image to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 사진 불러오는 함수\n",
    "def load_images(folder_path,file_names,img_size_shape):\n",
    "    images = []                                          # 불러올 사진을 담을 리스트\n",
    "    \n",
    "    for i in range(len(file_names)):\n",
    "        path = os.path.join(folder_path,file_names[i])   # 사진경로 생성\n",
    "        img = Image.open(path).resize(img_size_shape)    # 이미지 오픈 후 리사이징\n",
    "        img = img.convert('RGB')                         # PNG -> RGB\n",
    "        images.append(np.array(img))                     # numpy배열로 변환 후 리스트에 추가\n",
    "   \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tattoo_dir_list = os.listdir(train_path)   # 타투 폴더 이름 가져오기\n",
    "tattoo_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "# train data\n",
    "for tattoo_dir in tattoo_dir_list :\n",
    "    print(tattoo_dir)\n",
    "    path = os.path.join(folder_path,'train',tattoo_dir)  # 경로 만들기\n",
    "    file_names = os.listdir(path)                        # 파일 이름 얻기\n",
    "    data = load_images(path, file_names, (224,224))      # 이미지 로드\n",
    "    print(len(data))\n",
    "    y_train = y_train + [tattoo_dir] * len(data)         # 정답 만들기\n",
    "    X_train = X_train + data                             # 이미지 병합\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = []\n",
    "y_validation = []\n",
    "# validation data\n",
    "for tattoo_dir in tattoo_dir_list :\n",
    "    print(tattoo_dir)\n",
    "    path = os.path.join(folder_path,'validation',tattoo_dir)     # 경로 만들기\n",
    "    file_names = os.listdir(path)                                # 파일 이름 얻기\n",
    "    data = load_images(path, file_names, (224,224))              # 이미지 로드\n",
    "    print(len(data))\n",
    "    y_validation = y_validation + [tattoo_dir] * len(data)       # 정답 만들기\n",
    "    X_validation = X_validation + data                           # 이미지 병합\n",
    "\n",
    "X_validation = np.array(X_validation)\n",
    "y_validation = np.array(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_validation.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "# test data\n",
    "for tattoo_dir in tattoo_dir_list :\n",
    "    print(tattoo_dir)\n",
    "    path = os.path.join(folder_path,'test',tattoo_dir)           # 경로 만들기\n",
    "    file_names = os.listdir(path)                                # 파일 이름 얻기\n",
    "    data = load_images(path, file_names, (224,224))              # 이미지 로드\n",
    "    print(len(data))\n",
    "    y_test = y_test + [tattoo_dir] * len(data)                   # 정답 만들기\n",
    "    X_test = X_test + data                                       # 이미지 병합\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Dropout,Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = pd.get_dummies(y_train)\n",
    "y_validation_one_hot = pd.get_dummies(y_validation)\n",
    "y_test_one_hot = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG19\n",
    "\n",
    "conv_base = VGG19(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(224, 224, 3))\n",
    "print(conv_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "vgg19_model = Sequential()\n",
    "vgg19_model.add(conv_base)\n",
    "vgg19_model.add(Flatten())\n",
    "vgg19_model.add(Dense(256,activation='relu'))\n",
    "vgg19_model.add(Dense(6,activation='softmax'))\n",
    "print(vgg19_model.summary())\n",
    "conv_base.trainable=True\n",
    "print(len(vgg19_model.trainable_weights))\n",
    "conv_base.trainable=False\n",
    "print(len(vgg19_model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./model/Tattoo_10_Model_{epoch:03d}_{val_accuracy:.4f}.hdf5\"\n",
    "mckp = ModelCheckpoint(filepath = path,\n",
    "                      monitor = 'val_accuracy',\n",
    "                      verbose=1,\n",
    "                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg19_history = vgg19_model.fit(X_train,y_train_one_hot,\n",
    "         validation_data=(X_validation,y_validation_one_hot),\n",
    "         epochs = 7,\n",
    "         batch_size = 50,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "         callbacks=[mckp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5)) # 가로,세로 사이즈\n",
    "plt.plot(vgg19_history.history['loss'], label='loss')\n",
    "plt.plot(vgg19_history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5)) # 가로,세로 사이즈\n",
    "plt.plot(history2.history['accuracy'], label='accuracy')\n",
    "plt.plot(history2.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model.evaluate(X_test,y_test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 로딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "best_model = load_model('./model/Tattoo_10_Model_002_1.0000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(X_test,y_test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(asdfksdf):\n",
    "    \n",
    "    return 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "PATH = './엣지엣지/whale_21.jpg' ## 사용자가 그린 도안의 경로 넣기 자바에서 값을 어떻게 불러오지 변수가 있어야됨. 고정경로+이미지명\n",
    "#PATH = r'C:\\Users\\SM120\\Desktop\\Re\\.metadata\\.plugins\\org.eclipse.wst.server.core\\tmp0\\wtpwebapps\\Tattoo\\upload\\{}'.format(file_name)\n",
    "\n",
    "    \n",
    "img = Image.open(PATH).resize((224, 224))\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "tattoo_dir_list = ['고래', '꽃', '나비', '달', '십자가', '하트']\n",
    "\n",
    "best_model = load_model('./model/Tattoo_10_Model_002_1.0000.hdf5')\n",
    "predictions = best_model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(score)\n",
    "print(\n",
    "    \"\\nThis image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(tattoo_dir_list[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "\n",
    "fold_name = tattoo_dir_list[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fold_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1df026fa394c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 파일 경로 지정하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msearch_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\\\추려추려\\\\\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfold_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mcache_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\\\추려추려\\\\cache_avhash\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fold_name' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# 파일 경로 지정하기\n",
    "search_dir = os.getcwd() + \"\\\\추려추려\\\\\" + fold_name\n",
    "cache_dir = os.getcwd() + \"\\\\추려추려\\\\cache_avhash\"\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.mkdir(cache_dir)\n",
    "\n",
    "# 이미지 데이터를 Average Hash로 변화하기\n",
    "def average_hash(fname,size=16):\n",
    "    fname2 = fname[len(search_dir):]\n",
    "    \n",
    "    #이미지 캐시하기\n",
    "    cache_file = cache_dir + \"\\\\\" + fname2.replace('\\\\','_') + \".csv\"\n",
    "    if not os.path.exists(cache_file):  # 해시 생성하기\n",
    "        img = Image.open(fname)\n",
    "        img = img.convert('L').resize((size, size), Image.ANTIALIAS)\n",
    "        pixels = np.array(img.getdata()).reshape((size, size))\n",
    "        avg = pixels.mean()\n",
    "        px = 1 * (pixels > avg)\n",
    "        np.savetxt(cache_file, px, fmt=\"%.0f\", delimiter=\",\")\n",
    "    else: \n",
    "        px = np.loadtxt(cache_file, delimiter=\",\")\n",
    "    return px\n",
    "\n",
    "#해밍 거리 구하기\n",
    "def hamming_dist(a,b):\n",
    "    aa = a.reshape(1,-1)      # 1차원 배열로 변환\n",
    "    ab = b.reshape(1,-1)\n",
    "    dist = (aa != ab).sum()\n",
    "    return dist\n",
    "\n",
    "# 모든 폴더의 이미지 파일에 처리 적용하기\n",
    "def enum_all_files(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            fname = os.path.join(root,f)\n",
    "            if re.search(r'\\.(jpg|jpeg|png)$',fname):\n",
    "                yield fname\n",
    "\n",
    "def fine_image(fname, rate):\n",
    "    src = average_hash(fname)\n",
    "\n",
    "    for fname in enum_all_files(search_dir):\n",
    "        dst = average_hash(fname)\n",
    "        diff_r = hamming_dist(src, dst) / 256\n",
    "        #print(\"[check]\",fname)\n",
    "        if diff_r < rate:\n",
    "            yield (diff_r,fname)\n",
    "\n",
    "# 찾기\n",
    "#srcfile = search_dir + \"\\\\whale_28.jpg\"\n",
    "srcfile = PATH\n",
    "html = \"\"\n",
    "sim = list(fine_image(srcfile, 1.5))\n",
    "sim = sorted(sim[:5], key=lambda x:x[0])\n",
    "\n",
    "image_addr = []\n",
    "# 비슷한 이미지를 찾은 결과(해밍거리 0.25 미만)를 이렇게 html파일로 만들어서 저장\n",
    "for r,f in sim:\n",
    "    print(r,\">\",f)\n",
    "    s = '<div style=\"float:left;\"><h3>[차이 :' + str(r) + '-' + \\\n",
    "        os.path.basename(f) + ']</h3>' + \\\n",
    "        '<p><a href= \"' + f + '\"><img src=\"'+f+'\"width=400>'+ \\\n",
    "        '</a></p></div>'\n",
    "    html += s\n",
    "    image_addr.append(f)\n",
    "\n",
    "#HTML로 출력\n",
    "html = \"\"\"<html><head><meta charset=\"utf8\"></head> \n",
    "<body><h3>원래 이미지</h3><p>\n",
    "<img src='{0}' width=400></p>{1}\n",
    "</body></html>\"\"\".format(srcfile, html)\n",
    "\n",
    "with open(\"./avhash-search-output.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (1.31.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from protobuf>=3.9.2->tensorflow) (50.3.0.post20201006)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.16.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.22.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.10)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from flask) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from flask) (7.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from flask) (0.16.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from flask) (2.11.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sm120\\anaconda3\\envs\\deep\\lib\\site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, re\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# 이미지 데이터를 Average Hash로 변화하기\n",
    "def average_hash(fname,size=16):\n",
    "    fname2 = fname[len(search_dir):]\n",
    "    \n",
    "    #이미지 캐시하기\n",
    "    cache_file = cache_dir + \"\\\\\" + fname2.replace('\\\\','_') + \".csv\"\n",
    "    if not os.path.exists(cache_file):  # 해시 생성하기\n",
    "        img = Image.open(fname)\n",
    "        img = img.convert('L').resize((size, size), Image.ANTIALIAS)\n",
    "        pixels = np.array(img.getdata()).reshape((size, size))\n",
    "        avg = pixels.mean()\n",
    "        px = 1 * (pixels > avg)\n",
    "        np.savetxt(cache_file, px, fmt=\"%.0f\", delimiter=\",\")\n",
    "    else: \n",
    "        px = np.loadtxt(cache_file, delimiter=\",\")\n",
    "    return px\n",
    "\n",
    "#해밍 거리 구하기\n",
    "def hamming_dist(a,b):\n",
    "    aa = a.reshape(1,-1)      # 1차원 배열로 변환\n",
    "    ab = b.reshape(1,-1)\n",
    "    dist = (aa != ab).sum()\n",
    "    return dist\n",
    "\n",
    "# 모든 폴더의 이미지 파일에 처리 적용하기\n",
    "def enum_all_files(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            fname = os.path.join(root,f)\n",
    "            if re.search(r'\\.(jpg|jpeg|png)$',fname):\n",
    "                yield fname\n",
    "\n",
    "def fine_image(fname, rate):\n",
    "    src = average_hash(fname)\n",
    "\n",
    "    for fname in enum_all_files(search_dir):\n",
    "        dst = average_hash(fname)\n",
    "        diff_r = hamming_dist(src, dst) / 256\n",
    "        #print(\"[check]\",fname)\n",
    "        if diff_r < rate:\n",
    "            yield (diff_r,fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:9000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [26/Nov/2020 12:17:56] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:17:56] \"\u001b[33mGET /엣지엣지/butterfly_21.jpg HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002657A114B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:18:22] \"\u001b[32mGET /painting?file_name=myPainting%20(21)4.jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 고래 with a 35.22 percent confidence.\n",
      "고래\n",
      "./추려추려/고래\n",
      "0.23046875 > ./추려추려/고래\\0004.jpg\n",
      "0.26171875 > ./추려추려/고래\\0051.jpg\n",
      "0.28125 > ./추려추려/고래\\0059.jpg\n",
      "0.3125 > ./추려추려/고래\\0005.jpg\n",
      "0.328125 > ./추려추려/고래\\0042.jpg\n",
      "ok\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000266F1D7ABF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([0.12956251 0.12956251 0.12956251 0.12956251 0.12956251 0.35218742], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.22 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:19:05] \"\u001b[32mGET /painting?file_name=myPainting%20(25)1.jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19921875 > ./추려추려/하트\\0003.jpg\n",
      "0.20703125 > ./추려추려/하트\\0001.jpg\n",
      "0.20703125 > ./추려추려/하트\\0002.jpg\n",
      "0.3046875 > ./추려추려/하트\\0004.jpg\n",
      "0.32421875 > ./추려추려/하트\\0005.jpg\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:19:06] \"\u001b[37mGET /draw?img_url=./추려추려/하트\\0001.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:06] \"\u001b[37mGET /draw?img_url=./추려추려/하트\\0003.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:06] \"\u001b[37mGET /draw?img_url=./추려추려/하트\\0002.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:06] \"\u001b[37mGET /draw?img_url=./추려추려/하트\\0004.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:06] \"\u001b[37mGET /draw?img_url=./추려추려/하트\\0005.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026700F33D08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([0.12956251 0.12956251 0.12956251 0.35218737 0.12956251 0.12956251], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 달 with a 35.22 percent confidence.\n",
      "달\n",
      "./추려추려/달\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[32mGET /painting?file_name=myPainting%20(26).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15625 > ./추려추려/달\\0047.jpg\n",
      "0.16015625 > ./추려추려/달\\0029.jpg\n",
      "0.16796875 > ./추려추려/달\\0022.jpg\n",
      "0.23046875 > ./추려추려/달\\0010.jpg\n",
      "0.25390625 > ./추려추려/달\\0015.jpg\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[37mGET /draw?img_url=./추려추려/달\\0047.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[37mGET /draw?img_url=./추려추려/달\\0029.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[37mGET /draw?img_url=./추려추려/달\\0022.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[37mGET /draw?img_url=./추려추려/달\\0015.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[37mGET /draw?img_url=./추려추려/달\\0010.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026710B84EA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([0.13055666 0.3425506  0.13055666 0.13370791 0.13055666 0.13207164], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 꽃 with a 34.26 percent confidence.\n",
      "꽃\n",
      "./추려추려/꽃\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:22:11] \"\u001b[32mGET /painting?file_name=myPainting%20(27).jpg HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:22:11] \"\u001b[37mGET /draw?img_url=./추려추려/꽃\\0011.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14453125 > ./추려추려/꽃\\0011.jpg\n",
      "0.15234375 > ./추려추려/꽃\\0038.jpg\n",
      "0.16015625 > ./추려추려/꽃\\0029.jpg\n",
      "0.19921875 > ./추려추려/꽃\\0006.jpg\n",
      "0.37109375 > ./추려추려/꽃\\0005.jpg\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:22:12] \"\u001b[37mGET /draw?img_url=./추려추려/꽃\\0038.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:22:12] \"\u001b[37mGET /draw?img_url=./추려추려/꽃\\0006.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:22:12] \"\u001b[37mGET /draw?img_url=./추려추려/꽃\\0029.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:22:12] \"\u001b[37mGET /draw?img_url=./추려추려/꽃\\0005.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026561E700D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:24:00] \"\u001b[32mGET /painting?file_name=myPainting%20(28).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12956253 0.12956253 0.12956253 0.35218745 0.12956253 0.12956253], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 달 with a 35.22 percent confidence.\n",
      "달\n",
      "./추려추려/달\n",
      "0.27734375 > ./추려추려/달\\0022.jpg\n",
      "0.28515625 > ./추려추려/달\\0010.jpg\n",
      "0.28515625 > ./추려추려/달\\0029.jpg\n",
      "0.2890625 > ./추려추려/달\\0047.jpg\n",
      "0.30859375 > ./추려추려/달\\0015.jpg\n",
      "ok\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026700F33378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:24:27] \"\u001b[32mGET /painting?file_name=myPainting%20(29).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.13708018 0.13708007 0.13708007 0.1379597  0.21820395 0.23259604], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 23.26 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.1953125 > ./추려추려/하트\\0003.jpg\n",
      "0.21875 > ./추려추려/하트\\0002.jpg\n",
      "0.234375 > ./추려추려/하트\\0001.jpg\n",
      "0.31640625 > ./추려추려/하트\\0004.jpg\n",
      "0.3671875 > ./추려추려/하트\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026551C3EE18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:25:14] \"\u001b[32mGET /painting?file_name=myPainting%20(30).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12956251 0.12956251 0.12956251 0.12956251 0.12956251 0.35218742], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.22 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.296875 > ./추려추려/하트\\0001.jpg\n",
      "0.296875 > ./추려추려/하트\\0002.jpg\n",
      "0.3203125 > ./추려추려/하트\\0003.jpg\n",
      "0.375 > ./추려추려/하트\\0005.jpg\n",
      "0.37890625 > ./추려추려/하트\\0004.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026561F31C80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:25:30] \"\u001b[32mGET /painting?file_name=myPainting%20(31).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.29745942 0.13438928 0.134423   0.16486117 0.13438518 0.1344819 ], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 고래 with a 29.75 percent confidence.\n",
      "고래\n",
      "./추려추려/고래\n",
      "0.2578125 > ./추려추려/고래\\0059.jpg\n",
      "0.26953125 > ./추려추려/고래\\0051.jpg\n",
      "0.2890625 > ./추려추려/고래\\0042.jpg\n",
      "0.375 > ./추려추려/고래\\0005.jpg\n",
      "0.37890625 > ./추려추려/고래\\0004.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656E3DF268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([0.12991723 0.34878898 0.12991723 0.13153456 0.12991723 0.12992483], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 꽃 with a 34.88 percent confidence.\n",
      "꽃\n",
      "./추려추려/꽃\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:28:06] \"\u001b[32mGET /painting?file_name=myPainting%20(32).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2265625 > ./추려추려/꽃\\0006.jpg\n",
      "0.234375 > ./추려추려/꽃\\0011.jpg\n",
      "0.2578125 > ./추려추려/꽃\\0038.jpg\n",
      "0.2734375 > ./추려추려/꽃\\0029.jpg\n",
      "0.3203125 > ./추려추려/꽃\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656FDCB378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:29:47] \"\u001b[32mGET /painting?file_name=myPainting%20(33).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12958401 0.12958746 0.12962943 0.12962931 0.12958656 0.35198322], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.20 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.09375 > ./추려추려/하트\\0002.jpg\n",
      "0.171875 > ./추려추려/하트\\0003.jpg\n",
      "0.1875 > ./추려추려/하트\\0001.jpg\n",
      "0.27734375 > ./추려추려/하트\\0004.jpg\n",
      "0.375 > ./추려추려/하트\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026574B59A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:30:43] \"\u001b[32mGET /painting?file_name=myPainting%20(34).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12956251 0.12956254 0.12956251 0.12956251 0.12956251 0.35218734], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.22 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.08984375 > ./추려추려/하트\\0002.jpg\n",
      "0.19140625 > ./추려추려/하트\\0001.jpg\n",
      "0.19921875 > ./추려추려/하트\\0003.jpg\n",
      "0.2578125 > ./추려추려/하트\\0004.jpg\n",
      "0.42578125 > ./추려추려/하트\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656E3DF598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:30:59] \"\u001b[32mGET /painting?file_name=myPainting%20(32)1.jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12991723 0.34878898 0.12991723 0.13153456 0.12991723 0.12992483], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 꽃 with a 34.88 percent confidence.\n",
      "꽃\n",
      "./추려추려/꽃\n",
      "0.2265625 > ./추려추려/꽃\\0006.jpg\n",
      "0.234375 > ./추려추려/꽃\\0011.jpg\n",
      "0.2578125 > ./추려추려/꽃\\0038.jpg\n",
      "0.2734375 > ./추려추려/꽃\\0029.jpg\n",
      "0.3203125 > ./추려추려/꽃\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026551C3EE18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:31:25] \"\u001b[32mGET /painting?file_name=myPainting%20(35).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12956251 0.12956251 0.12956251 0.12956251 0.12956251 0.35218742], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.22 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.140625 > ./추려추려/하트\\0002.jpg\n",
      "0.171875 > ./추려추려/하트\\0001.jpg\n",
      "0.1953125 > ./추려추려/하트\\0003.jpg\n",
      "0.26171875 > ./추려추려/하트\\0004.jpg\n",
      "0.3671875 > ./추려추려/하트\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656FDCB488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:31:48] \"\u001b[32mGET /painting?file_name=myPainting%20(36).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.1295667  0.12956963 0.1295667  0.12958257 0.1295667  0.35214773], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.21 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.125 > ./추려추려/하트\\0002.jpg\n",
      "0.1484375 > ./추려추려/하트\\0001.jpg\n",
      "0.2265625 > ./추려추려/하트\\0003.jpg\n",
      "0.26953125 > ./추려추려/하트\\0004.jpg\n",
      "0.40625 > ./추려추려/하트\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656E5BA268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:33:52] \"\u001b[32mGET /painting?file_name=myPainting%20(37).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.13045754 0.13043751 0.13043751 0.34368256 0.13454707 0.13043788], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 달 with a 34.37 percent confidence.\n",
      "달\n",
      "./추려추려/달\n",
      "0.21484375 > ./추려추려/달\\0010.jpg\n",
      "0.2421875 > ./추려추려/달\\0047.jpg\n",
      "0.24609375 > ./추려추려/달\\0029.jpg\n",
      "0.25390625 > ./추려추려/달\\0022.jpg\n",
      "0.28515625 > ./추려추려/달\\0015.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000267026432F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:34:36] \"\u001b[32mGET /painting?file_name=myPainting%20(38).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12968104 0.12966403 0.1300986  0.3512214  0.12966403 0.12967089], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 달 with a 35.12 percent confidence.\n",
      "달\n",
      "./추려추려/달\n",
      "0.18359375 > ./추려추려/달\\0022.jpg\n",
      "0.18359375 > ./추려추려/달\\0029.jpg\n",
      "0.1875 > ./추려추려/달\\0047.jpg\n",
      "0.22265625 > ./추려추려/달\\0010.jpg\n",
      "0.23046875 > ./추려추려/달\\0015.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656FD309D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([0.12976204 0.12976621 0.35029545 0.12986012 0.1305545  0.12976162], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 나비 with a 35.03 percent confidence.\n",
      "나비\n",
      "./추려추려/나비\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[32mGET /painting?file_name=myPainting%20(39).jpg HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[37mGET /draw?img_url=./추려추려/나비\\0042.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16796875 > ./추려추려/나비\\0042.jpg\n",
      "0.171875 > ./추려추려/나비\\0027.jpg\n",
      "0.25390625 > ./추려추려/나비\\0001.jpg\n",
      "0.26953125 > ./추려추려/나비\\0018.jpg\n",
      "0.3515625 > ./추려추려/나비\\0004.jpg\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[37mGET /draw?img_url=./추려추려/나비\\0027.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[37mGET /draw?img_url=./추려추려/나비\\0001.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[37mGET /draw?img_url=./추려추려/나비\\0018.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[37mGET /draw?img_url=./추려추려/나비\\0004.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026710BA51E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 14:42:45] \"\u001b[32mGET /painting?file_name=myPainting%20(21)5.jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 고래 with a 35.22 percent confidence.\n",
      "고래\n",
      "./추려추려/고래\n",
      "0.23046875 > ./추려추려/고래\\0004.jpg\n",
      "0.26171875 > ./추려추려/고래\\0051.jpg\n",
      "0.28125 > ./추려추려/고래\\0059.jpg\n",
      "0.3125 > ./추려추려/고래\\0005.jpg\n",
      "0.328125 > ./추려추려/고래\\0042.jpg\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, redirect, url_for, request, Response, render_template\n",
    "from flask import send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/draw/flower', methods = ['POST', 'GET'])\n",
    "def draw():\n",
    "    num = 3\n",
    "    \n",
    "    return send_file('./추려추려/' + str(num) + '.jpg', mimetype='image/jpeg')\n",
    "\n",
    "@app.route('/draw', methods = ['POST', 'GET'])\n",
    "def draw2():\n",
    "\n",
    "    return send_file(request.args['img_url'], mimetype='image/jpeg')\n",
    "\n",
    "@app.route('/', methods = ['POST', 'GET'])\n",
    "def home():\n",
    "    return render_template('avhash-search-output.html') #localhost:9000 기본 서버 열었을 때 템플릿으로 이동 아무것도 없는 껍데기\n",
    "\n",
    "\n",
    "#자바 서블릿단에서 파일명 받아와서 동작하는 함수\n",
    "@app.route('/painting', methods = ['POST', 'GET'])\n",
    "def painting():\n",
    "    file_name = request.args['file_name']\n",
    " \n",
    "    #PATH = './엣지엣지/butterfly_21.jpg' ## 사용자가 그린 도안의 경로 넣기 자바에서 값을 어떻게 불러오지 변수가 있어야됨. 고정경로+이미지명\n",
    "    PATH = r'C:\\Users\\SM120\\Desktop\\Re\\.metadata\\.plugins\\org.eclipse.wst.server.core\\tmp0\\wtpwebapps\\Tattoo\\upload\\{}'.format(file_name)\n",
    "\n",
    "        # 이미지 데이터를 Average Hash로 변화하기\n",
    "    def average_hash(fname,size=16):\n",
    "        fname2 = fname[len(search_dir):]\n",
    "\n",
    "        #이미지 캐시하기\n",
    "        cache_file = cache_dir + \"\\\\\" + fname2.replace('\\\\','_') + \".csv\"\n",
    "        if not os.path.exists(cache_file):  # 해시 생성하기\n",
    "            img = Image.open(fname)\n",
    "            img = img.convert('L').resize((size, size), Image.ANTIALIAS)\n",
    "            pixels = np.array(img.getdata()).reshape((size, size))\n",
    "            avg = pixels.mean()\n",
    "            px = 1 * (pixels > avg)\n",
    "            np.savetxt(cache_file, px, fmt=\"%.0f\", delimiter=\",\")\n",
    "        else: \n",
    "            px = np.loadtxt(cache_file, delimiter=\",\")\n",
    "        return px\n",
    "\n",
    "    #해밍 거리 구하기\n",
    "    def hamming_dist(a,b):\n",
    "        aa = a.reshape(1,-1)      # 1차원 배열로 변환\n",
    "        ab = b.reshape(1,-1)\n",
    "        dist = (aa != ab).sum()\n",
    "        return dist\n",
    "\n",
    "    # 모든 폴더의 이미지 파일에 처리 적용하기\n",
    "    def enum_all_files(path):\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for f in files:\n",
    "                fname = os.path.join(root,f)\n",
    "                if re.search(r'\\.(jpg|jpeg|png)$',fname):\n",
    "                    yield fname\n",
    "\n",
    "    def fine_image(fname, rate):\n",
    "        src = average_hash(fname)\n",
    "\n",
    "        for fname in enum_all_files(search_dir):\n",
    "            dst = average_hash(fname)\n",
    "            diff_r = hamming_dist(src, dst) / 256\n",
    "            #print(\"[check]\",fname)\n",
    "            if diff_r < rate:\n",
    "                yield (diff_r,fname)\n",
    "\n",
    "            \n",
    "    img = Image.open(PATH).resize((224, 224))\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    tattoo_dir_list = ['고래', '꽃', '나비', '달', '십자가', '하트']\n",
    "\n",
    "    best_model = load_model('./model/Tattoo_10_Model_002_1.0000.hdf5')\n",
    "    predictions = best_model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    print(score)\n",
    "    print(\n",
    "        \"\\nThis image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(tattoo_dir_list[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n",
    "\n",
    "    fold_name = tattoo_dir_list[np.argmax(score)]   \n",
    "    print(fold_name)\n",
    "\n",
    "    # 파일 경로 지정하기\n",
    "    #search_dir = './templates/' + fold_name\n",
    "    search_dir = './추려추려/' + fold_name\n",
    "    print(search_dir) #추려추려/이름\n",
    "    cache_dir = './추려추려/cache_avhash'\n",
    "\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.mkdir(cache_dir)\n",
    "        \n",
    "    # 찾기\n",
    "    srcfile = PATH\n",
    "    html = \"\"\n",
    "    sim = list(fine_image(srcfile, 1.5))\n",
    "    sim = sorted(sim[:5], key=lambda x:x[0])\n",
    "\n",
    "    image_addr = [] \n",
    "    # 비슷한 이미지를 찾은 결과(해밍거리 0.25 미만)를 이렇게 html파일로 만들어서 저장\n",
    "    for r,f in sim:\n",
    "        print(r,\">\",f)\n",
    "        s = '<div style=\"float:left;\"><h3>[차이 :' + str(r) + '-' + \\\n",
    "            os.path.basename(f) + ']</h3>' + \\\n",
    "            '<p><a href= \"' + f + '\"><img src=\"'+f+'\"width=400>'+ \\\n",
    "            '</a></p></div>'\n",
    "        html += s\n",
    "        image_addr.append(f)\n",
    "        \n",
    "\n",
    "    #HTML로 출력\n",
    "    html = \"\"\"<html><head><meta charset=\"utf8\"></head> \n",
    "    <body><h3>원래 이미지</h3><p>\n",
    "    <img src='{0}' width=400></p>{1}\n",
    "    </body></html>\"\"\".format(srcfile, html)\n",
    "\n",
    "    with open(\"./avhash-search-output.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    print(\"ok\") #여기까지 잘 됨.\n",
    "\n",
    "    \n",
    "    #이 주소가 아니라 다른 다른 \n",
    "    #return render_template('avhash-search-output.html')\n",
    "\n",
    "    #http://localhost:9000/painting?file_name={}.format(file_name)  이 주소로 이동하면서 사진도 띄워야됨\n",
    "\n",
    "    # redirect로  값을 반환해주는 페이지 이동하면서 이미지도 가져감..  쿼리스트링으로 배열은 못넘기고 대신 ,를 써서 join으로넘김\n",
    "    # cnn.result 로 가려면 저기 주소 바꿔야한다.\n",
    "    return redirect('http://localhost:8088/Tattoo/avhash-search-output.jsp?file_name={}'.format(\",\".join(image_addr)))\n",
    "    \n",
    "    print(\"ok2\")\n",
    "\n",
    "\n",
    "    \n",
    "# 무조건 맨 마지막    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"localhost\", port=\"9000\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
